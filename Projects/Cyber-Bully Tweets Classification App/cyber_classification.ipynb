{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the project\n",
    "Cyberbullying is a serious issue that affects many individuals, particularly youth, on social media platforms. One way to combat cyberbullying is through the use of machine learning to classify tweets as bullying or non-bullying. This project aims to develop a model that can accurately classify tweets as cyberbullying or non-cyberbullying. The model will be trained on a dataset of labeled tweets and will use natural language processing techniques to identify patterns and features that are indicative of cyberbullying. The ultimate goal of the project is to provide a tool that can help identify and mitigate cyberbullying on social media."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import PorterStemmer, WordNetLemmatizer\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('cyberbullying_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47692 entries, 0 to 47691\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   tweet_text          47692 non-null  object\n",
      " 1   cyberbullying_type  47692 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 745.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47692, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text            0\n",
       "cyberbullying_type    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding of categorical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cyberbullying_type   cyberbullying_type_encoded\n",
       "religion             5                             7998\n",
       "age                  0                             7992\n",
       "gender               2                             7973\n",
       "ethnicity            1                             7961\n",
       "not_cyberbullying    3                             7945\n",
       "other_cyberbullying  4                             7823\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "data['cyberbullying_type_encoded'] = labelencoder.fit_transform(data['cyberbullying_type'])\n",
    "data[['cyberbullying_type', 'cyberbullying_type_encoded']].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_lower(text):\n",
    "    return text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
    "             'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
    "             'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
    "             'does', 'doing', 'down', 'during', 'each','few', 'for', 'from',\n",
    "             'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
    "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
    "             'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
    "             'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
    "             'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're',\n",
    "             's', 'same', 'she', \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
    "             't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
    "             'themselves', 'then', 'there', 'these', 'they', 'this', 'those',\n",
    "             'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',\n",
    "             'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
    "             'why', 'will', 'with', 'won', 'y', 'you', \"youd\",\"youll\", \"youre\",\n",
    "             \"youve\", 'your', 'yours', 'yourself', 'yourselves']\n",
    "    STOPWORDS = set(stopwordlist)\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_punct(text):\n",
    "    eng_punct = string.punctuation\n",
    "    translator = str.maketrans('','', eng_punct)\n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rep_char(text):\n",
    "    return re.sub(r'(.)1+', r'1', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_URLs(text):\n",
    "    return re.sub(r\"((www.[^s]+)|(http\\S+))\",\"\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric(text):\n",
    "    return re.sub('[0-9]+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweet(text):\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    text = text.apply(tokenizer.tokenize)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_stemming(text):\n",
    "    st = PorterStemmer()\n",
    "    text = [st.stem(word) for word in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_lemmatization(text):\n",
    "    lm = WordNetLemmatizer()\n",
    "    text = [lm.lemmatize(word) for word in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>cyberbullying_type_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word katandandr food crapilici mkr</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aussietv white mkr theblock imacelebrityau tod...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xochitlsuckkk classi whore red velvet cupcak</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jasongio meh p thank head up but not concern a...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rudhoeenglish isi account pretend kurdish acco...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>black ppl arent expect anyth depend anyth yet ...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>turner not withhold disappoint turner call cou...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>swear god dumb nigger bitch got bleach hair re...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>yea fuck rt therealexel nigger fuck unfollow m...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>bro u gotta chill rt chillshrammi dog fuck kp ...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47692 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text cyberbullying_type  \\\n",
       "0                     word katandandr food crapilici mkr  not_cyberbullying   \n",
       "1      aussietv white mkr theblock imacelebrityau tod...  not_cyberbullying   \n",
       "2           xochitlsuckkk classi whore red velvet cupcak  not_cyberbullying   \n",
       "3      jasongio meh p thank head up but not concern a...  not_cyberbullying   \n",
       "4      rudhoeenglish isi account pretend kurdish acco...  not_cyberbullying   \n",
       "...                                                  ...                ...   \n",
       "47687  black ppl arent expect anyth depend anyth yet ...          ethnicity   \n",
       "47688  turner not withhold disappoint turner call cou...          ethnicity   \n",
       "47689  swear god dumb nigger bitch got bleach hair re...          ethnicity   \n",
       "47690  yea fuck rt therealexel nigger fuck unfollow m...          ethnicity   \n",
       "47691  bro u gotta chill rt chillshrammi dog fuck kp ...          ethnicity   \n",
       "\n",
       "       cyberbullying_type_encoded  \n",
       "0                               3  \n",
       "1                               3  \n",
       "2                               3  \n",
       "3                               3  \n",
       "4                               3  \n",
       "...                           ...  \n",
       "47687                           1  \n",
       "47688                           1  \n",
       "47689                           1  \n",
       "47690                           1  \n",
       "47691                           1  \n",
       "\n",
       "[47692 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    text = txt_lower(text)\n",
    "    text = text.apply(lambda text: remove_stopwords(text))\n",
    "    text = text.apply(lambda x : clean_punct(x))\n",
    "    text = text.apply(lambda x: clean_rep_char(x))\n",
    "    text = text.apply(lambda x : clean_URLs(x))\n",
    "    text = text.apply(lambda x: clean_numeric(x))\n",
    "    text = tokenize_tweet(text)\n",
    "    text = text.apply(lambda x: text_stemming(x))\n",
    "    text = text.apply(lambda x: text_lemmatization(x))\n",
    "    text = text.apply(lambda x : \" \".join(x))\n",
    "    return text\n",
    "\n",
    "data['tweet_text'] = preprocess(data['tweet_text'])\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data['tweet_text'], data['cyberbullying_type_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.25, random_state= 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature words:  328865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Transforming the data using TF-IDF Vectorizer\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features= 500000)\n",
    "vectoriser.fit(X_train)\n",
    "print(\"No. of feature words: \",len(vectoriser.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping the vectoriser\n",
    "pickle.dump(vectoriser, open('tdf_vectorizer', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectoriser.transform(X_train)\n",
    "X_test = vectoriser.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of the model on SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827224691772205\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "svm_model_linear = SVC(kernel= 'linear', C = 1).fit(X_train, y_train)\n",
    "svm_predictions  = svm_model_linear.predict(X_test)\n",
    "accuracy = svm_model_linear.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumping the model\n",
    "pickle.dump(svm_model_linear, open('model.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of a Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for custom input prediction\n",
    "def custom_input_prediction(text):\n",
    "    import nltk\n",
    "    nltk.download('omw-1.4')\n",
    "    text = pd.Series(text)\n",
    "    text = preprocess(text)\n",
    "    text = [text[0],]\n",
    "    vectoriser = pickle.load(open(\"tdf_vectorizer\", \"rb\"))\n",
    "    text = vectoriser.transform(text)\n",
    "    model = pickle.load(open(\"model.pkl\", \"rb\"))\n",
    "    prediction = model.predict(text)\n",
    "    prediction = prediction[0]\n",
    "\n",
    "    interpretations = {\n",
    "        0 : \"Age\",\n",
    "        1 : \"Ethnicity\",\n",
    "        2 : \"Gender\",\n",
    "        3 : \"Not Cyberbullying\",\n",
    "        4 : \"Other Cyberbullying\",\n",
    "        5 : \"Religion\"\n",
    "    }\n",
    "\n",
    "    for i in interpretations.keys():\n",
    "        if i == prediction:\n",
    "            return interpretations[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n"
     ]
    }
   ],
   "source": [
    "example1 = \"My Grandsons are angry about this gender free crap too! 2 in primary 2 @at high school T.he is 16 yr old ASD &amp; got bullied as did a girl in his SEN base. He had to step in as teachers to busy on phones playing games, wee lass would have had nowhere to run if loos unisex!\"\n",
    "print(custom_input_prediction(example1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
